<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <property name="app.name" value="aop.search"/>
    <!--<property name="LOG_HOME" value="/usr/local/src/logs"/>-->
    <property name="LOG_HOME" value="D:\work\logs"/>

    <!--  输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <!-- 普通打印,不带traceId -->
        <!--
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
        -->
        <!-- 带traceId -->
        <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
            <layout class="org.apache.skywalking.apm.toolkit.log.logback.v1.x.TraceIdPatternLogbackLayout">
                <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level logger_name:%logger{36} - [%tid] - message:%msg%n</pattern>
            </layout>
        </encoder>
    </appender>

    <!-- info日志输出 -->
    <appender name="INFO" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/info.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/info.log.%d{yyyy-MM-dd}</FileNamePattern>
            <!-- 日志文件保留天数 -->
            <MaxHistory>90</MaxHistory>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!-- 格式化输出:%d表示日期 %thread表示线程名 %-5level:级别从左显示5个字符宽度  %msg:日志消息  %n换行符 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss}|%F|%M|%msg%n</pattern>
        </encoder>
        <!-- 只输出INFO日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 过滤INFO -->
            <level>INFO</level>
            <!-- 匹配到就禁止 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 没有匹配到就允许 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>


    <!-- error日志输出 -->
    <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/error.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/error.log.%d{yyyy-MM-dd}</FileNamePattern>
            <!-- 日志文件保留天数 -->
            <MaxHistory>90</MaxHistory>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!-- 格式化输出:%d表示日期 %thread表示线程名 %-5level:级别从左显示5个字符宽度  %msg:日志消息  %n换行符 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss}|%F|%M|%msg%n</pattern>
        </encoder>
        <!-- 只打印错误日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- debug日志输出 -->
    <appender name="DEBUG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/debug.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/debug.log.%d{yyyy-MM-dd}</FileNamePattern>
            <!-- 日志文件保留天数 -->
            <MaxHistory>90</MaxHistory>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!-- 格式化输出:%d表示日期 %thread表示线程名 %-5level:级别从左显示5个字符宽度  %msg:日志消息  %n换行符 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss}|%F|%M|%msg%n</pattern>
        </encoder>
    </appender>


    <!-- 业务日志输出 -->
    <appender name="BUSINESS" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_HOME}/business.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/business.log.%d{yyyy-MM-dd}</FileNamePattern>
            <!-- 日志文件保留天数 -->
            <MaxHistory>90</MaxHistory>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!-- 格式化输出:%d表示日期 %thread表示线程名 %-5level:级别从左显示5个字符宽度  %msg:日志消息  %n换行符 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss}|%F|%M|%msg%n</pattern>
        </encoder>
    </appender>


    <!-- 输出到kafka -->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
            <layout class="org.apache.skywalking.apm.toolkit.log.logback.v1.x.TraceIdPatternLogbackLayout">
                <pattern>
                    {
                    "app": "${app.name}",
                    "level": "%level",
                    "logger": "%logger{36}",
                    "method": "%method",
                    "message": "%replace(%replace(%msg){'\"','\''}){'[\r\n\t]+',' '}",
                    "tid": "%tid",
                    "ex": "%replace(%replace(%ex{20}){'\"', '\''}){'[\r\n\t]+',' '}"
                    }
                </pattern>
            </layout>
        </encoder>
        <topic>prod-log-kafka</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
        <producerConfig>bootstrap.servers=192.168.222.129:9092</producerConfig>
        <!-- 不需要等待服务器确认 -->
        <producerConfig>acks=0</producerConfig>
        <!-- 等待1000毫秒,然后批量提交日志 -->
        <producerConfig>linger.ms=1000</producerConfig>
        <!-- 内存缓冲区大小 -->
        <producerConfig>buffer.memory=64000000</producerConfig>
        <producerConfig>batch.size=8000</producerConfig>
        <!-- 缓冲区满的时候,不阻塞程序,采用下面配置进行日志输出 -->
        <producerConfig>max.block.ms=0</producerConfig>
        <!-- kafka连接失败后,使用下面配置进行日志输出 -->
        <appender-ref ref="BUSINESS"/>
    </appender>

    <!-- 关闭org.apache.kafka包下的日志输出 -->
    <logger name="org.apache.kafka" level="OFF"/>

    <!-- grpc上报日志 v8.4.0提供 -->
    <appender name="grpc-log" class="org.apache.skywalking.apm.toolkit.log.logback.v1.x.log.GRPCLogClientAppender">
    </appender>

    <root level="info">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="INFO"/>
        <appender-ref ref="ERROR"/>
        <appender-ref ref="kafkaAppender"/>
        <appender-ref ref="grpc-log"/>
    </root>
</configuration>